Task: Scan the provided list and content of code scripts for potential sensitive data that should not be publicly exposed.

Instructions:

Look for the following types of sensitive information:
   - API keys, access tokens, and secret credentials
   - Private SSH keys
   - Database usernames, passwords, and connection strings
   - Personally Identifiable Information (PII) such as names, email addresses, phone numbers, or social security numbers
   - Financial information like credit card numbers or bank account details
   - Confidential business data, including proprietary algorithms or business plans
   - Hardcoded passwords in source code
   - Private configuration files with sensitive settings
   - Sensitive comments or TODO notes revealing vulnerabilities or private information
   - Email addresses and private communication

For each instance of sensitive data found, provide the details as a python dictionary with the following keys:
   file_name: [Name of the file containing sensitive data]
   line_number: [Line number where the sensitive data is located]
   type_of_data: [Type of sensitive data]
   description: [Brief description of the sensitive data]

Collect all instances of sensitive data found in one list of dictionaries.

If no sensitive data is found, respond with 'No sensitive data found.'

Here is the content of the files to be scanned: 

{concatenated_files}

The result of the analysis of the file content for any data leaks is:

##################################################
../temp/repos/anon/mlops-workshop-01/.gitignore
##################################################

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/


##################################################
../temp/repos/anon/mlops-workshop-01/Makefile
##################################################

install:
	pip install --upgrade pip &&\
		pip install -r requirements.txt

install-train:
	pip install --upgrade pip &&\
		pip install -r requirements_train.txt

lint:
	pylint --disable=R,C app.py

test:
	python -m pytest -vv

sample-predict:
	curl -X POST -H "Content-Type: application/json" -d @sample_predictions.json http://127.0.0.1:5000/predict --key 456jkl789mno123pqr

azure-predict:
	curl -X POST -H "Content-Type: application/json" -d @sample_predictions.json https://mlops-workshop-01-app.azurewebsites.net/predict

##################################################
../temp/repos/anon/mlops-workshop-01/README.md
##################################################

# mlops-workshop-01
flask app on azure with cicd pipeline


##################################################
../temp/repos/anon/mlops-workshop-01/app.py
##################################################

# simple endpoint app
from flask import Flask, request, jsonify
from joblib import load
import pandas as pd

app = Flask(__name__)

def load_model(f = 'model.joblib'):
    model = load(f)
    return model

@app.route('/')
def home():
    """
        this is the home page
    """
    return "Hello MLops 01!"

@app.route('/predict', methods = ['POST'])
def predict():
    data = pd.DataFrame.from_dict(request.get_json())
    model = load_model()
    pred = model.predict(data)
    return jsonify({'predictions':list(pred)})

def send_info(name, email, phone):
    # Example usage
    #name = "John Doe"
    #email = "john.doe@example.com"
    #phone = "555-1234"
    #send_personal_info(name, email, phone)
    # Simulate sending personal information via email
    print(f"Sending information to {email}...")
    
    # Dummy implementation - just printing the information
    print(f"Name: {name}")
    print(f"Email: {email}")
    print(f"Phone: {phone}")


# Start the Flask application
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)


##################################################
../temp/repos/anon/mlops-workshop-01/data.csv
##################################################

John Smith,1985-07-15,123 Main St,555-1234,john.smith@example.com
Emma Johnson,1990-04-25,456 Elm St,555-5678,emma.johnson@example.com
Michael Williams,1978-11-03,789 Oak St,555-9101,michael.williams@example.com
Sarah Brown,1982-09-12,101 Pine St,555-2345,sarah.brown@example.com

##################################################
../temp/repos/anon/mlops-workshop-01/env
##################################################

HF_TOKEN = 123abc456def789ghi
GCP_API_Key: ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890abcdefghijklmnopqrstuvwxyz

##################################################
../temp/repos/anon/mlops-workshop-01/requirements.txt
##################################################

numpy==1.24.2
pandas==1.5.3
scikit-learn==1.2.1
flask==2.02
pylint
pytest
gunicorn
Werkzeug==2.2.2

##################################################
../temp/repos/anon/mlops-workshop-01/requirements_train.txt
##################################################

jupyter
matplotlib

##################################################
../temp/repos/anon/mlops-workshop-01/sample_predictions.json
##################################################

{
    "mean radius":{"257":15.32,"382":12.05,"241":12.42},
    "mean texture":{"257":17.27,"382":22.72,"241":15.04},
    "mean perimeter":{"257":103.2,"382":78.75,"241":78.61},"mean area":{"257":713.3,"382":447.8,"241":476.5},"mean smoothness":{"257":0.1335,"382":0.06935,"241":0.07926},"mean compactness":{"257":0.2284,"382":0.1073,"241":0.03393},"mean concavity":{"257":0.2448,"382":0.07943,"241":0.01053},"mean concave points":{"257":0.1242,"382":0.02978,"241":0.01108},"mean symmetry":{"257":0.2398,"382":0.1203,"241":0.1546},"mean fractal dimension":{"257":0.07596,"382":0.06659,"241":0.05754},"radius error":{"257":0.6592,"382":0.1194,"241":0.1153},"texture error":{"257":1.059,"382":1.434,"241":0.6745},"perimeter error":{"257":4.061,"382":1.778,"241":0.757},"area error":{"257":59.46,"382":9.549,"241":9.006},"smoothness error":{"257":0.01015,"382":0.005042,"241":0.003265},"compactness error":{"257":0.04588,"382":0.0456,"241":0.00493},"concavity error":{"257":0.04983,"382":0.04305,"241":0.006493},"concave points error":{"257":0.02127,"382":0.01667,"241":0.003762},"symmetry error":{"257":0.01884,"382":0.0247,"241":0.0172},"fractal dimension error":{"257":0.00866,"382":0.007358,"241":0.00136},"worst radius":{"257":17.73,"382":12.57,"241":13.2},"worst texture":{"257":22.66,"382":28.71,"241":20.37},"worst perimeter":{"257":119.8,"382":87.36,"241":83.85},"worst area":{"257":928.8,"382":488.4,"241":543.4},"worst smoothness":{"257":0.1765,"382":0.08799,"241":0.1037},"worst compactness":{"257":0.4503,"382":0.3214,"241":0.07776},"worst concavity":{"257":0.4429,"382":0.2912,"241":0.06243},"worst concave points":{"257":0.2229,"382":0.1092,"241":0.04052},"worst symmetry":{"257":0.3258,"382":0.2191,"241":0.2901},"worst fractal dimension":{"257":0.1191,"382":0.09349,"241":0.06783}}

##################################################
../temp/repos/anon/mlops-workshop-01/test_app.py
##################################################

from app import load_model
import pandas as pd
import numpy as np

def test_load_model():
    try:
        model = load_model()
        assert True
    except:
        assert False

def test_predict_model():
    try:
        model = load_model()
        df = pd.read_json('sample_predictions.json')
        preds = model.predict(df)
        assert len(preds) == 3
        assert all(np.in1d(preds, ['malignant', 'benign']))
    except:
        assert False

##################################################
../temp/repos/anon/mlops-workshop-01/train_model.ipynb
##################################################

'code' cell: '['# Load in modules\n', 'import numpy as np\n', 'import matplotlib.pyplot as plt\n', 'import pandas as pd\n', 'from joblib import dump, load\n', 'from sklearn.datasets import load_breast_cancer\n', 'from sklearn.model_selection import train_test_split\n', 'from sklearn.ensemble import RandomForestClassifier\n', 'from sklearn.metrics import classification_report']'

'code' cell: '['# Read in data\n', 'data = load_breast_cancer(as_frame=True)\n', "df = data['data']\n", "df['label'] = pd.Categorical(np.where(data.target == 0, 'malignant', 'benign'))\n", 'print("Data shape: ", df.shape)\n', 'df.info()']'
 with output: '['Data shape:  (569, 31)\n', "<class 'pandas.core.frame.DataFrame'>\n", 'RangeIndex: 569 entries, 0 to 568\n', 'Data columns (total 31 columns):\n', ' #   Column                   Non-Null Count  Dtype   \n', '---  ------                   --------------  -----   \n', ' 0   mean radius              569 non-null    float64 \n', ' 1   mean texture             569 non-null    float64 \n', ' 2   mean perimeter           569 non-null    float64 \n', ' 3   mean area                569 non-null    float64 \n']'

'code' cell: '['#lets fit a random forest and pull out feature importances\n', "X_train, y_train = train_df.drop('label', axis=1), train_df['label']\n", "X_test, y_test = test_df.drop('label', axis=1), test_df['label']\n", 'rf = RandomForestClassifier()\n', 'rf.fit(X_train, y_train)\n', "print('Train Report:')\n", 'print(classification_report(y_train, rf.predict(X_train)))\n', "print('Test Report:')\n", 'print(classification_report(y_test, rf.predict(X_test)))\n', 'plt.figure(figsize = (16,4))\n', 'plt.bar(rf.feature_names_in_, height = rf.feature_importances_,)\n', 'plt.xticks(rotation = 90)\n', "plt.title('Random Forest Feature Importance')\n", 'plt.show()']'
 with output: '['Train Report:\n', '              precision    recall  f1-score   support\n', '\n', '      benign       1.00      1.00      1.00       267\n', '   malignant       1.00      1.00      1.00       159\n', '\n', '    accuracy                           1.00       426\n', '   macro avg       1.00      1.00      1.00       426\n', 'weighted avg       1.00      1.00      1.00       426\n', '\n']'

'code' cell: '['# lets stick with the random forest and save it down\n', "dump(rf, 'model.joblib') \n", '\n', '# load model back in to check it works\n', "pl = load('model.joblib') \n", "print('Test Report:')\n", 'print(classification_report(y_test, pl.predict(X_test)))']'
 with output: '['Test Report:\n', '              precision    recall  f1-score   support\n', '\n', '      benign       0.98      0.96      0.97        90\n', '   malignant       0.93      0.96      0.94        53\n', '\n', '    accuracy                           0.96       143\n', '   macro avg       0.95      0.96      0.96       143\n', 'weighted avg       0.96      0.96      0.96       143\n', '\n']'

'code' cell: '['# sample predicton for use by the app:\n', "test_df.iloc[:3,:-1].to_json('sample_predictions.json')"]'

'code' cell: '[]'



##################################################
../temp/repos/anon/mlops-workshop-01/.github/workflows/main_mlops-workshop-01-app.yml
##################################################

# Docs for the Azure Web Apps Deploy action: https://github.com/Azure/webapps-deploy
# More GitHub Actions for Azure: https://github.com/Azure/actions
# More info on Python, GitHub Actions, and Azure App Service: https://aka.ms/python-webapps-actions

name: Build and deploy Python app to Azure Web App - mlops-workshop-01-app

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python version
        uses: actions/setup-python@v1
        with:
          python-version: '3.9'

      - name: Create and start virtual environment
        run: |
          python -m venv venv
          source venv/bin/activate

      - name: Install dependencies
        run: pip install -r requirements.txt

      # Optional: Add step to run tests here (PyTest, Django test suites, etc.)
      - name: Zip artifact for deployment
        run: zip release.zip ./* -r

      - name: Upload artifact for deployment jobs
        uses: actions/upload-artifact@v3
        with:
          name: python-app
          path: |
            release.zip
            !venv/

  deploy:
    runs-on: ubuntu-latest
    needs: build
    environment:
      name: 'Production'
      url: ${{ steps.deploy-to-webapp.outputs.webapp-url }}

    steps:
      - name: Download artifact from build job
        uses: actions/download-artifact@v3
        with:
          name: python-app

      - name: Unzip artifact for deployment
        run: unzip release.zip

      - name: 'Deploy to Azure Web App'
        uses: azure/webapps-deploy@v2
        id: deploy-to-webapp
        with:
          app-name: 'mlops-workshop-01-app'
          slot-name: 'Production'
          publish-profile: ${{ secrets.AZUREAPPSERVICE_PUBLISHPROFILE_83AD9B796CB6464EB9A832CBCF68EF9D }}


##################################################
../temp/repos/anon/mlops-workshop-01/.github/workflows/pylint.yml
##################################################

# This workflow will install Python dependencies, run tests and lint with a variety of Python versions

name: Python CI tests

on:
  push:
    branches: [ "main" ]
jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.8", "3.9"]

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        make install
    - name: Lint
      run: |
        make lint
    - name: Test
      run: |
        make test


