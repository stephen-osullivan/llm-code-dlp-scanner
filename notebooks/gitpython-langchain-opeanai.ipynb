{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sos00/projects/llm-code-dlp-scanner/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit: 7fdfcce6c8759d086fd2b6e1b72da2c0fccbaf94 Author: stephen-osullivan Date: 2024-05-02 11:09:24+00:00\n",
      "Message: checked working with llamacpp\n",
      "\n",
      "\n",
      "Commit: 6bc6cb57334394ad5367c876a87abf1ec76245ef Author: stephen-osullivan Date: 2024-05-02 10:17:20+00:00\n",
      "Message: added image to readme, fixed a hardcoded url\n",
      "\n",
      "\n",
      "Commit: f8d5c28d4ba45b4f51c1381a6387d8fb9c21d71a Author: stephen-osullivan Date: 2024-05-01 16:26:03+00:00\n",
      "Message: added docker launch command\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from git import Repo\n",
    "\n",
    "!rm -rf repos/chat-app\n",
    "repo_url = \"https://github.com/stephen-osullivan/streamlit-openai-chatbot.git\"\n",
    "repo_local_path = \"repos/chat-app\"\n",
    "# Clone the repository\n",
    "repo = Repo.clone_from(repo_url, repo_local_path)\n",
    "\n",
    "# show last 3 commits\n",
    "for _, commit in zip(range(3), repo.iter_commits()):\n",
    "    print(f\"Commit: {commit.hexsha}\", f\"Author: {commit.author}\", f\"Date: {commit.committed_datetime}\")\n",
    "    print(f\"Message: {commit.message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".gitignore - 3087 bytes\n",
      "Dockerfile - 225 bytes\n",
      "Makefile - 472 bytes\n",
      "README.md - 679 bytes\n",
      "app.py - 4108 bytes\n",
      "demo.png - 166996 bytes\n",
      "requirements.txt - 60 bytes\n"
     ]
    }
   ],
   "source": [
    "# Get a specific commit\n",
    "commit_hash = \"7fdfcce6c8759d086fd2b6e1b72da2c0fccbaf94\"\n",
    "commit = repo.commit(commit_hash)\n",
    "\n",
    "import os\n",
    "tree = commit.tree\n",
    "\n",
    "# Traverse the tree and list files with their sizes\n",
    "for blob in tree.traverse():\n",
    "    if blob.type == \"blob\":\n",
    "        file_path = os.path.join(repo_local_path, blob.path)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        print(f\"{blob.path} - {file_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed files since the previous commit:\n",
      "demo.png, size: 163.08 KBs\n",
      "README.md, size: 0.66 KBs\n",
      "Makefile, size: 0.46 KBs\n",
      ".gitignore, size: 3.01 KBs\n",
      "app.py, size: 4.01 KBs\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository (or use Repo.init_from_url for a remote repo)\n",
    "repo_path = repo_local_path\n",
    "repo = Repo(repo_path)\n",
    "\n",
    "# Get the current commit\n",
    "current_commit = repo.commit(\"HEAD\")\n",
    "\n",
    "diffs = current_commit.diff(\"0f19dedaed9994626d76deab206ec3d1664a25bf\")\n",
    "# Find all changed files\n",
    "changed_files = set()\n",
    "for change_type in [\"A\", \"M\", \"D\"]:  # A: added, M: modified, D: deleted\n",
    "    for changed_file in diffs.iter_change_type(change_type):\n",
    "        changed_files.add(changed_file.b_path)\n",
    "\n",
    "# Print the changed files\n",
    "print(\"Changed files since the previous commit:\")\n",
    "for file_path in changed_files:\n",
    "    full_file_path = os.path.join(repo_local_path, file_path)\n",
    "    file_size = os.path.getsize(full_file_path)\n",
    "    print(f'{file_path}, size: {file_size/1024:.2f} KBs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### langchain document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the changed files into LangChain documents\u001b[39;00m\n\u001b[1;32m      4\u001b[0m documents \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load the changed files into LangChain documents\n",
    "documents = []\n",
    "for file_path in changed_files:\n",
    "    full_path = os.path.join(repo_path, file_path)\n",
    "    if (os.path.getsize(full_file_path) < 10 * 1024): # less than 10kb \n",
    "        try:\n",
    "            loader = TextLoader(full_path, autodetect_encoding=True)\n",
    "            documents.extend(loader.load())\n",
    "        except:\n",
    "            print('Failed to decode:', file_path)\n",
    "\n",
    "# Now you can use the 'documents' list with LangChain\n",
    "print(f\"Loaded {len(documents)} documents from the changed files.\")\n",
    "doc_names = [doc.metadata['source'] for doc in documents]\n",
    "print(doc_names)\n",
    "print('Lengths:', [(n, len(doc.page_content)) for n, doc in zip(doc_names, documents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate, MessagesPlaceholder\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "load_dotenv\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.3, \n",
    "    max_tokens = 1000)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", 'You are an expert at reading and understanding code repositories.'),\n",
    "        (\"human\", \"Please could you summarise this file for me:\\nfile name {file_name}\\n\\n file_contents:\\n{file_contents}\"),\n",
    "    ])\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "doc = documents[0]\n",
    "chain.invoke(dict(file_name=doc.metadata['source'], file_contents = doc.page_content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
